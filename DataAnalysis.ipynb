{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "In this notebook we study the error in our numerical method as well as preform various sanity checks on the results. These are:\n",
    "1. Ploting the RMSv\n",
    "2. Ploting the Error in Energy Conservation as a function of timestep size\n",
    "3. Generating contour plots at various timesteps to compare with the results of Schaer and Wernli's paper for the initial condition of an isolated Semi-Geostrophic Cyclone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the needed packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from solvers import mainHeun as Heun\n",
    "from solvers import mainRK4 as RK4\n",
    "from solvers import mainAB2 as AB2\n",
    "from solvers import mainCN as CN\n",
    "import erroranalysis as err\n",
    "import auxfunctions as aux\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZRef, CRef, WRef, MRef, TCRef = aux.load_data('./PaperData/RK4_SG_data_10-3_32_15.msgpack')\n",
    "box = [-3.66, -1.75, 0, 3.66, 1.75, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1, C1, _, _, _ = aux.load_data('./PaperData/RK4_SG_data_A=-0.5.msgpack')\n",
    "Z2, C2, _, _, _ = aux.load_data('./PaperData/RK4_SG_data_A=0.msgpack')\n",
    "Z3, C3, _, _, _ = aux.load_data('./PaperData/RK4_SG_data_A=0.1.msgpack')\n",
    "box = [-3.66, -1.75, 0, 3.66, 1.75, 0.45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "Z, C, W, M, TC = aux.load_data('./PaperData/RK4_SG_data_10-3_32_1hr30.msgpack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Here we investigate the Wasserstein-2 Distance. These are done by comparison to a \"high-resolution\" simulation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Wasserstein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 403\n",
      "2 of 403\n",
      "3 of 403\n",
      "4 of 403\n",
      "5 of 403\n",
      "6 of 403\n",
      "7 of 403\n",
      "8 of 403\n",
      "9 of 403\n",
      "10 of 403\n",
      "11 of 403\n",
      "12 of 403\n",
      "13 of 403\n",
      "14 of 403\n",
      "15 of 403\n",
      "16 of 403\n",
      "17 of 403\n",
      "18 of 403\n",
      "19 of 403\n",
      "20 of 403\n",
      "21 of 403\n",
      "22 of 403\n",
      "23 of 403\n",
      "24 of 403\n",
      "25 of 403\n",
      "26 of 403\n",
      "27 of 403\n",
      "28 of 403\n",
      "29 of 403\n",
      "30 of 403\n",
      "31 of 403\n",
      "32 of 403\n",
      "33 of 403\n",
      "34 of 403\n",
      "35 of 403\n",
      "36 of 403\n",
      "37 of 403\n",
      "38 of 403\n",
      "39 of 403\n",
      "40 of 403\n",
      "41 of 403\n",
      "42 of 403\n",
      "43 of 403\n",
      "44 of 403\n",
      "45 of 403\n",
      "46 of 403\n",
      "47 of 403\n",
      "48 of 403\n",
      "49 of 403\n",
      "50 of 403\n",
      "51 of 403\n",
      "52 of 403\n",
      "53 of 403\n",
      "54 of 403\n",
      "55 of 403\n",
      "56 of 403\n",
      "57 of 403\n",
      "58 of 403\n",
      "59 of 403\n",
      "60 of 403\n",
      "61 of 403\n",
      "62 of 403\n",
      "63 of 403\n",
      "64 of 403\n",
      "65 of 403\n",
      "66 of 403\n",
      "67 of 403\n",
      "68 of 403\n",
      "69 of 403\n",
      "70 of 403\n",
      "71 of 403\n",
      "72 of 403\n",
      "73 of 403\n",
      "74 of 403\n",
      "75 of 403\n",
      "76 of 403\n",
      "77 of 403\n",
      "78 of 403\n",
      "79 of 403\n",
      "80 of 403\n",
      "81 of 403\n",
      "82 of 403\n",
      "83 of 403\n",
      "84 of 403\n",
      "85 of 403\n",
      "86 of 403\n",
      "87 of 403\n",
      "88 of 403\n",
      "89 of 403\n",
      "90 of 403\n",
      "91 of 403\n",
      "92 of 403\n",
      "93 of 403\n",
      "94 of 403\n",
      "95 of 403\n",
      "96 of 403\n",
      "97 of 403\n",
      "98 of 403\n",
      "99 of 403\n",
      "100 of 403\n",
      "101 of 403\n",
      "102 of 403\n",
      "103 of 403\n",
      "104 of 403\n",
      "105 of 403\n",
      "106 of 403\n",
      "107 of 403\n",
      "108 of 403\n",
      "109 of 403\n",
      "110 of 403\n",
      "111 of 403\n",
      "112 of 403\n",
      "113 of 403\n",
      "114 of 403\n",
      "115 of 403\n",
      "116 of 403\n",
      "117 of 403\n",
      "118 of 403\n",
      "119 of 403\n",
      "120 of 403\n",
      "121 of 403\n",
      "122 of 403\n",
      "123 of 403\n",
      "124 of 403\n",
      "125 of 403\n",
      "126 of 403\n",
      "127 of 403\n",
      "128 of 403\n",
      "129 of 403\n",
      "130 of 403\n",
      "131 of 403\n",
      "132 of 403\n",
      "133 of 403\n",
      "134 of 403\n",
      "135 of 403\n",
      "136 of 403\n",
      "137 of 403\n",
      "138 of 403\n",
      "139 of 403\n",
      "140 of 403\n",
      "141 of 403\n",
      "142 of 403\n",
      "143 of 403\n",
      "144 of 403\n",
      "145 of 403\n",
      "146 of 403\n",
      "147 of 403\n",
      "148 of 403\n",
      "149 of 403\n",
      "150 of 403\n",
      "151 of 403\n",
      "152 of 403\n",
      "153 of 403\n",
      "154 of 403\n",
      "155 of 403\n",
      "156 of 403\n",
      "157 of 403\n",
      "158 of 403\n",
      "159 of 403\n",
      "160 of 403\n",
      "161 of 403\n",
      "162 of 403\n",
      "163 of 403\n",
      "164 of 403\n",
      "165 of 403\n",
      "166 of 403\n",
      "167 of 403\n",
      "168 of 403\n",
      "169 of 403\n",
      "170 of 403\n",
      "171 of 403\n",
      "172 of 403\n",
      "173 of 403\n",
      "174 of 403\n",
      "175 of 403\n",
      "176 of 403\n",
      "177 of 403\n",
      "178 of 403\n",
      "179 of 403\n",
      "180 of 403\n",
      "181 of 403\n",
      "182 of 403\n",
      "183 of 403\n",
      "184 of 403\n",
      "185 of 403\n",
      "186 of 403\n",
      "187 of 403\n",
      "188 of 403\n",
      "189 of 403\n",
      "190 of 403\n",
      "191 of 403\n",
      "192 of 403\n",
      "193 of 403\n",
      "194 of 403\n",
      "195 of 403\n",
      "196 of 403\n",
      "197 of 403\n",
      "198 of 403\n",
      "199 of 403\n",
      "200 of 403\n",
      "201 of 403\n",
      "202 of 403\n",
      "203 of 403\n",
      "204 of 403\n",
      "205 of 403\n",
      "206 of 403\n",
      "207 of 403\n",
      "208 of 403\n",
      "209 of 403\n",
      "210 of 403\n",
      "211 of 403\n",
      "212 of 403\n",
      "213 of 403\n",
      "214 of 403\n",
      "215 of 403\n",
      "216 of 403\n",
      "217 of 403\n",
      "218 of 403\n",
      "219 of 403\n",
      "220 of 403\n",
      "221 of 403\n",
      "222 of 403\n",
      "223 of 403\n",
      "224 of 403\n",
      "225 of 403\n",
      "226 of 403\n",
      "227 of 403\n",
      "228 of 403\n",
      "229 of 403\n",
      "230 of 403\n",
      "231 of 403\n",
      "232 of 403\n",
      "233 of 403\n",
      "234 of 403\n",
      "235 of 403\n",
      "236 of 403\n",
      "237 of 403\n",
      "238 of 403\n",
      "239 of 403\n",
      "240 of 403\n",
      "241 of 403\n",
      "242 of 403\n",
      "243 of 403\n",
      "244 of 403\n",
      "245 of 403\n",
      "246 of 403\n",
      "247 of 403\n",
      "248 of 403\n",
      "249 of 403\n",
      "250 of 403\n",
      "251 of 403\n",
      "252 of 403\n",
      "253 of 403\n",
      "254 of 403\n",
      "255 of 403\n",
      "256 of 403\n",
      "257 of 403\n",
      "258 of 403\n",
      "259 of 403\n",
      "260 of 403\n",
      "261 of 403\n",
      "262 of 403\n",
      "263 of 403\n",
      "264 of 403\n",
      "265 of 403\n",
      "266 of 403\n",
      "267 of 403\n",
      "268 of 403\n",
      "269 of 403\n",
      "270 of 403\n",
      "271 of 403\n",
      "272 of 403\n",
      "273 of 403\n",
      "274 of 403\n",
      "275 of 403\n",
      "276 of 403\n",
      "277 of 403\n",
      "278 of 403\n",
      "279 of 403\n",
      "280 of 403\n",
      "281 of 403\n",
      "282 of 403\n",
      "283 of 403\n",
      "284 of 403\n",
      "285 of 403\n",
      "286 of 403\n",
      "287 of 403\n",
      "288 of 403\n",
      "289 of 403\n",
      "290 of 403\n",
      "291 of 403\n",
      "292 of 403\n",
      "293 of 403\n",
      "294 of 403\n",
      "295 of 403\n",
      "296 of 403\n",
      "297 of 403\n",
      "298 of 403\n",
      "299 of 403\n",
      "300 of 403\n",
      "301 of 403\n",
      "302 of 403\n",
      "303 of 403\n",
      "304 of 403\n",
      "305 of 403\n",
      "306 of 403\n",
      "307 of 403\n",
      "308 of 403\n",
      "309 of 403\n",
      "310 of 403\n",
      "311 of 403\n",
      "312 of 403\n",
      "313 of 403\n",
      "314 of 403\n",
      "315 of 403\n",
      "316 of 403\n",
      "317 of 403\n",
      "318 of 403\n",
      "319 of 403\n",
      "320 of 403\n",
      "321 of 403\n",
      "322 of 403\n",
      "323 of 403\n",
      "324 of 403\n",
      "325 of 403\n",
      "326 of 403\n",
      "327 of 403\n",
      "328 of 403\n",
      "329 of 403\n",
      "330 of 403\n",
      "331 of 403\n",
      "332 of 403\n",
      "333 of 403\n",
      "334 of 403\n",
      "335 of 403\n",
      "336 of 403\n",
      "337 of 403\n",
      "338 of 403\n",
      "339 of 403\n",
      "340 of 403\n",
      "341 of 403\n",
      "342 of 403\n",
      "343 of 403\n",
      "344 of 403\n",
      "345 of 403\n",
      "346 of 403\n",
      "347 of 403\n",
      "348 of 403\n",
      "349 of 403\n",
      "350 of 403\n",
      "351 of 403\n",
      "352 of 403\n",
      "353 of 403\n",
      "354 of 403\n",
      "355 of 403\n",
      "356 of 403\n",
      "357 of 403\n",
      "358 of 403\n",
      "359 of 403\n",
      "360 of 403\n",
      "361 of 403\n",
      "362 of 403\n",
      "363 of 403\n",
      "364 of 403\n",
      "365 of 403\n",
      "366 of 403\n",
      "367 of 403\n",
      "368 of 403\n",
      "369 of 403\n",
      "370 of 403\n",
      "371 of 403\n",
      "372 of 403\n",
      "373 of 403\n",
      "374 of 403\n",
      "375 of 403\n",
      "376 of 403\n",
      "377 of 403\n",
      "378 of 403\n",
      "379 of 403\n",
      "380 of 403\n",
      "381 of 403\n",
      "382 of 403\n",
      "383 of 403\n",
      "384 of 403\n",
      "385 of 403\n",
      "386 of 403\n",
      "387 of 403\n",
      "388 of 403\n",
      "389 of 403\n",
      "390 of 403\n",
      "391 of 403\n",
      "392 of 403\n",
      "393 of 403\n",
      "394 of 403\n",
      "395 of 403\n",
      "396 of 403\n",
      "397 of 403\n",
      "398 of 403\n",
      "399 of 403\n",
      "400 of 403\n",
      "401 of 403\n",
      "402 of 403\n",
      "403 of 403\n",
      "1.1480658054351807\n"
     ]
    }
   ],
   "source": [
    "comptimes = aux.get_comparison_indices(len(Z), len(ZRef), 52)\n",
    "distances = err.Wasserstein_Distance(Z, M, ZRef, MRef, comptimes)\n",
    "error = max(distances)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timesteps\n",
    "timesteps = 52 / np.array([201, 302, 403, 604, 804, 1207])\n",
    "# Error at Day 2\n",
    "errors_day_2 = np.array([0.0091, 0.0022, 0.0014, 0.0007, 0.0004, 5.2552e-5])\n",
    "errors_day_4 = np.array([0.0223, 0.0071, 0.0055, 0.0032, 0.0025, 0.0017])\n",
    "errors_day_9 = np.array([0.0866, 0.0393, 0.0428, 0.0351, 0.0331, 0.0246])\n",
    "errors_day_13 = np.array([0.3650, 0.1865, 0.1645, 0.1377, 0.1433, 0.0939])\n",
    "errors_day_17 = np.array([0.6162, 0.5765, 0.6625, 0.7114, 0.3229, 0.4740])\n",
    "errors_day_21 = np.array([0.5932, 0.7715, 0.9556, 0.9401, 0.5205, 0.9702])\n",
    "errors_day_25 = np.array([0.9808, 0.8195, 0.8565, 1.0594, 0.4602, 0.6124])\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each day's error\n",
    "plt.loglog(timesteps, errors_day_2, 'o-', label='Day 2')\n",
    "plt.loglog(timesteps, errors_day_4, 's-', label='Day 4')\n",
    "plt.loglog(timesteps, errors_day_9, 'd-', label='Day 9')\n",
    "plt.loglog(timesteps, errors_day_13, 'x-', label='Day 13')\n",
    "plt.loglog(timesteps, errors_day_17, '^-', label='Day 17')\n",
    "plt.loglog(timesteps, errors_day_21, 'v-', label='Day 21')\n",
    "plt.loglog(timesteps, errors_day_25, 'p-', label='Day 25')\n",
    "\n",
    "# Plotting the reference line for h^4 reduction for Day 2\n",
    "reference_errors_day_2 = errors_day_2[0] * (timesteps / timesteps[0])**4  # scale factor for reference line\n",
    "plt.loglog(timesteps, reference_errors_day_2, '--', label='Reference: $h^4$')\n",
    "\n",
    "# Customizing x-axis labels\n",
    "labels = ['3 hr', '2 hr', '1 hr 30 m', '1 hr', '45 m', '30 m']\n",
    "plt.xticks(timesteps, labels, rotation=45)  # Rotate labels to avoid overlap\n",
    "plt.minorticks_off()  # Disable minor ticks\n",
    "\n",
    "plt.xlabel('Log of Timestep size')\n",
    "plt.ylabel('Log of Error')\n",
    "plt.title('Log Error vs. Log Timestep Size')\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "# Placing the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timesteps\n",
    "timesteps = 52 / np.array([201, 302, 403, 604, 804, 1207])\n",
    "\n",
    "# Days\n",
    "days = np.array([2, 4, 9, 13, 17, 21, 25])\n",
    "\n",
    "# Errors\n",
    "errors_day_2 = np.array([0.0091, 0.0022, 0.0014, 0.0007, 0.0004, 5.2552e-5])\n",
    "errors_day_4 = np.array([0.0223, 0.0071, 0.0055, 0.0032, 0.0025, 0.0017])\n",
    "errors_day_9 = np.array([0.0866, 0.0393, 0.0428, 0.0351, 0.0331, 0.0246])\n",
    "errors_day_13 = np.array([0.3650, 0.1865, 0.1645, 0.1377, 0.1433, 0.0939])\n",
    "errors_day_17 = np.array([0.6162, 0.5765, 0.6625, 0.7114, 0.3229, 0.4740])\n",
    "errors_day_21 = np.array([0.5932, 0.7715, 0.9556, 0.9401, 0.5205, 0.9702])\n",
    "errors_day_25 = np.array([0.9808, 0.8195, 0.8565, 1.0594, 0.4602, 0.6124])\n",
    "\n",
    "# Combine all errors into a single array for easier plotting\n",
    "errors = np.array([errors_day_2, errors_day_4, errors_day_9, errors_day_13, errors_day_17, errors_day_21, errors_day_25])\n",
    "\n",
    "# Take the log of the errors\n",
    "log_errors = np.log10(errors)\n",
    "\n",
    "# Reference error behavior: h^4 reduction\n",
    "initial_error = errors_day_2[0]\n",
    "reference_errors = np.zeros_like(errors)\n",
    "for i in range(len(timesteps)):\n",
    "    reference_errors[:, i] = initial_error * (timesteps[i] / timesteps[0])**4\n",
    "\n",
    "# Take the log of the reference errors\n",
    "log_reference_errors = np.log10(reference_errors)\n",
    "\n",
    "# Calculate the difference between actual errors and reference errors\n",
    "log_difference_errors = log_errors - log_reference_errors\n",
    "\n",
    "# Determine the color limits based on the combined range of log_errors, log_reference_errors, and log_difference_errors\n",
    "vmin = min(np.min(log_errors), np.min(log_reference_errors), np.min(log_difference_errors))\n",
    "vmax = max(np.max(log_errors), np.max(log_reference_errors), np.max(log_difference_errors))\n",
    "\n",
    "# Create a 2D heatmap with shared color bar\n",
    "fig, axs = plt.subplots(1, 3, figsize=(30, 6))\n",
    "\n",
    "# Plot the original heatmap with log(errors)\n",
    "c1 = axs[0].imshow(log_errors, aspect='auto', interpolation='nearest', cmap='viridis', origin='lower', vmin=vmin, vmax=vmax)\n",
    "axs[0].set_xlabel('Log of Timestep size')\n",
    "axs[0].set_ylabel('Days')\n",
    "axs[0].set_title('Log of Error')\n",
    "axs[0].set_xticks(np.arange(len(timesteps)))\n",
    "axs[0].set_xticklabels(np.log10(timesteps).round(2))\n",
    "axs[0].set_yticks(np.arange(len(days)))\n",
    "axs[0].set_yticklabels(days)\n",
    "\n",
    "# Plot the reference heatmap with log(reference errors)\n",
    "c2 = axs[1].imshow(log_reference_errors, aspect='auto', interpolation='nearest', cmap='viridis', origin='lower', vmin=vmin, vmax=vmax)\n",
    "axs[1].set_xlabel('Log of Timestep size')\n",
    "axs[1].set_ylabel('Days')\n",
    "axs[1].set_title('Log of Reference Error')\n",
    "axs[1].set_xticks(np.arange(len(timesteps)))\n",
    "axs[1].set_xticklabels(np.log10(timesteps).round(2))\n",
    "axs[1].set_yticks(np.arange(len(days)))\n",
    "axs[1].set_yticklabels(days)\n",
    "\n",
    "# Plot the difference heatmap with log(difference errors)\n",
    "c3 = axs[2].imshow(log_difference_errors, aspect='auto', interpolation='nearest', cmap='viridis', origin='lower', vmin=vmin, vmax=vmax)\n",
    "axs[2].set_xlabel('Log of Timestep size')\n",
    "axs[2].set_ylabel('Days')\n",
    "axs[2].set_title('Log of Difference between Actual and Reference Error')\n",
    "axs[2].set_xticks(np.arange(len(timesteps)))\n",
    "axs[2].set_xticklabels(np.log10(timesteps).round(2))\n",
    "axs[2].set_yticks(np.arange(len(days)))\n",
    "axs[2].set_yticklabels(days)\n",
    "\n",
    "# Create a single color bar for all three plots\n",
    "cbar = fig.colorbar(c1, ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Log of Error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of particles\n",
    "particles = np.array([4096, 5832, 10648, 21952])\n",
    "\n",
    "# Errors at different days\n",
    "errors_day_2 = np.array([0.1600, 0.1233, 0.0699, 0.0246])\n",
    "errors_day_4 = np.array([0.2594, 0.1503, 0.0939, 0.0315])\n",
    "errors_day_9 = np.array([0.6186, 0.4656, 0.3040, 0.1190])\n",
    "errors_day_13 = np.array([1.3901, 1.0459, 0.5674, 0.7100])\n",
    "errors_day_17 = np.array([1.8708, 1.4215, 0.9495, 0.7642])\n",
    "errors_day_21 = np.array([1.9466, 1.3115, 1.2798, 1.4379])\n",
    "errors_day_25 = np.array([1.4330, 0.8541, 0.9993, 0.8179])\n",
    "\n",
    "# Reference line for perfect halving behavior\n",
    "reference_errors = errors_day_2[0] * (particles[0] / particles)**(2/3)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each day's error\n",
    "plt.loglog(particles, errors_day_2, 'o-', label='Day 2')\n",
    "plt.loglog(particles, errors_day_4, 's-', label='Day 4')\n",
    "plt.loglog(particles, errors_day_9, 'd-', label='Day 9')\n",
    "plt.loglog(particles, errors_day_13, 'x-', label='Day 13')\n",
    "plt.loglog(particles, errors_day_17, '^-', label='Day 17')\n",
    "plt.loglog(particles, errors_day_21, 'v-', label='Day 21')\n",
    "plt.loglog(particles, errors_day_25, 'p-', label='Day 25')\n",
    "\n",
    "# Plotting the reference line for perfect halving behavior\n",
    "plt.loglog(particles, reference_errors, '--', label='Reference: $N^{-1/2}$')\n",
    "\n",
    "# Customizing x-axis labels to be the number of particles\n",
    "plt.xticks(particles, particles, rotation=45)  # Rotate labels to avoid overlap\n",
    "plt.minorticks_off()  # Disable minor ticks\n",
    "\n",
    "plt.xlabel('Number of Particles')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Log Error vs. Log Number of Particles')\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "\n",
    "# Placing the legend outside the plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Number of particles\n",
    "particles = np.array([4096, 5832, 10648, 21952])\n",
    "\n",
    "# Days\n",
    "days = np.array([2, 4, 9, 13, 17, 21, 25])\n",
    "\n",
    "# Errors at different days\n",
    "errors_day_2 = np.array([0.1600, 0.1233, 0.0699, 0.0246])\n",
    "errors_day_4 = np.array([0.2594, 0.1503, 0.0939, 0.0315])\n",
    "errors_day_9 = np.array([0.6186, 0.4656, 0.3040, 0.1190])\n",
    "errors_day_13 = np.array([1.3901, 1.0459, 0.5674, 0.7100])\n",
    "errors_day_17 = np.array([1.8708, 1.4215, 0.9495, 0.7642])\n",
    "errors_day_21 = np.array([1.9466, 1.3115, 1.2798, 1.4379])\n",
    "errors_day_25 = np.array([1.4330, 0.8541, 0.9993, 0.8179])\n",
    "\n",
    "# Combine all errors into a single array for easier plotting\n",
    "errors = np.array([errors_day_2, errors_day_4, errors_day_9, errors_day_13, errors_day_17, errors_day_21, errors_day_25])\n",
    "\n",
    "# Take the log of the errors\n",
    "log_errors = np.log10(errors)\n",
    "\n",
    "# Reference error behavior: error decreases as N^(-1/2)\n",
    "reference_errors = np.zeros_like(errors)\n",
    "for i in range(len(particles)):\n",
    "    reference_errors[:, i] = errors_day_2[0] * (particles[0] / particles[i])**0.5\n",
    "\n",
    "# Take the log of the reference errors\n",
    "log_reference_errors = np.log10(reference_errors)\n",
    "\n",
    "# Calculate the difference between actual errors and reference errors\n",
    "log_difference_errors = log_errors - log_reference_errors\n",
    "\n",
    "# Determine the color limits based on the combined range of log_errors, log_reference_errors, and log_difference_errors\n",
    "vmin = min(np.min(log_errors), np.min(log_reference_errors), np.min(log_difference_errors))\n",
    "vmax = max(np.max(log_errors), np.max(log_reference_errors), np.max(log_difference_errors))\n",
    "\n",
    "# Create a 2D heatmap with shared color bar\n",
    "fig, axs = plt.subplots(1, 3, figsize=(30, 6))\n",
    "\n",
    "# Plot the original heatmap with log(errors)\n",
    "c1 = axs[0].imshow(log_errors, aspect='auto', interpolation='nearest', cmap='viridis', origin='lower', vmin=vmin, vmax=vmax)\n",
    "axs[0].set_xlabel('Log of Number of Particles')\n",
    "axs[0].set_ylabel('Days')\n",
    "axs[0].set_title('Log of Error')\n",
    "axs[0].set_xticks(np.arange(len(particles)))\n",
    "axs[0].set_xticklabels(np.log10(particles).round(2))\n",
    "axs[0].set_yticks(np.arange(len(days)))\n",
    "axs[0].set_yticklabels(days)\n",
    "\n",
    "# Plot the reference heatmap with log(reference errors)\n",
    "c2 = axs[1].imshow(log_reference_errors, aspect='auto', interpolation='nearest', cmap='viridis', origin='lower', vmin=vmin, vmax=vmax)\n",
    "axs[1].set_xlabel('Log of Number of Particles')\n",
    "axs[1].set_ylabel('Days')\n",
    "axs[1].set_title('Log of Reference Error')\n",
    "axs[1].set_xticks(np.arange(len(particles)))\n",
    "axs[1].set_xticklabels(np.log10(particles).round(2))\n",
    "axs[1].set_yticks(np.arange(len(days)))\n",
    "axs[1].set_yticklabels(days)\n",
    "\n",
    "# Plot the difference heatmap with log(difference errors)\n",
    "c3 = axs[2].imshow(log_difference_errors, aspect='auto', interpolation='nearest', cmap='viridis', origin='lower', vmin=vmin, vmax=vmax)\n",
    "axs[2].set_xlabel('Log of Number of Particles')\n",
    "axs[2].set_ylabel('Days')\n",
    "axs[2].set_title('Log of Difference between Actual and Reference Error')\n",
    "axs[2].set_xticks(np.arange(len(particles)))\n",
    "axs[2].set_xticklabels(np.log10(particles).round(2))\n",
    "axs[2].set_yticks(np.arange(len(days)))\n",
    "axs[2].set_yticklabels(days)\n",
    "\n",
    "# Create a single color bar for all three plots\n",
    "cbar = fig.colorbar(c1, ax=axs, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "cbar.set_label('Log of Error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next we have our coding sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the RMSv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Define the datasets\n",
    "datasets = [(Z1, C1), (Z2, C2), (Z3, C3)]\n",
    "colors = ['red', 'blue', 'green']\n",
    "labels = ['A=-0.5', 'A=0', 'A=0.1']\n",
    "\n",
    "# A list of the three types to plot\n",
    "types = ['Zonal', 'Meridional', 'Total']\n",
    "\n",
    "# Calculate the number of timesteps based on one of the datasets (assuming all have the same length)\n",
    "timesteps = np.arange(len(Z1))\n",
    "\n",
    "# Convert timesteps to days (each timestep is 30 minutes, hence divide by 48)\n",
    "days = timesteps / 48\n",
    "\n",
    "for plot_type in types:\n",
    "    plt.figure()  # Create a new figure for each type of velocity\n",
    "    for (ZRef, CRef), color, label in zip(datasets, colors, labels):\n",
    "        # Calculate RMS velocity for the current type\n",
    "        RMSv = err.Root_Mean_Squared_Velocity(ZRef, CRef, plot_type)\n",
    "        \n",
    "        # Create a line plot\n",
    "        plt.plot(days, RMSv, color=color, label=label)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel(f'{plot_type} RMSv')\n",
    "    plt.title(f'{plot_type} RMSv Over Time')\n",
    "    \n",
    "    # Add legend to differentiate the datasets\n",
    "    plt.legend()\n",
    "    \n",
    "    # Save the plot as a PNG file with DPI=300\n",
    "    plt.savefig(f'RMSv_{plot_type}.png', dpi=300)\n",
    "    \n",
    "    # Optionally, show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking that the Transport Cost is Conserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary for maping files\n",
    "solver_name_map = {\n",
    "    AB2: 'AB2',\n",
    "    Heun: 'Heun',\n",
    "    RK4: 'RK4',\n",
    "    CN: 'CN'\n",
    "}\n",
    "\n",
    "# Define the parameters of the system\n",
    "box = [-2, -1, 0, 2, 1, 0.5] # List or tuple defining domain [xmin, ymin, zmin, xmax, ymax, zmax]\n",
    "per_tol = 1e-3 # Percent tolerance\n",
    "per_x = True # Set the periodicity of X\n",
    "per_y = False # Set the periodicity of Y\n",
    "per_z = False # Set the periodicity of Z\n",
    "tf = 26 # Final time\n",
    "Ndt = np.linspace(20, 2000, 20, endpoint=True) # Number of timesteps\n",
    "N = 10 # Number of seeds\n",
    "Z = np.array([(random.uniform(box[0], box[3]),\n",
    "               random.uniform(box[1], box[4]),\n",
    "               random.uniform(box[2], box[5])) for _ in range(N)]) # Place the seeds randomly\n",
    "\n",
    "# Function to run a solver test and compute metrics\n",
    "def run_test(solver, box, Z, per_tol, tf, Ndt, per_x, per_y, per_z, debug=False):\n",
    "    \"\"\"\n",
    "    Runs a specific solver and returns conservation error and runtime.\n",
    "\n",
    "    Parameters:\n",
    "    - solver: The solver function to run.\n",
    "    - box, Z, per_tol, tf, Ndt, per_x, per_y, per_z: Parameters for the solver.\n",
    "    - debug: Whether to run the solver in debug mode.\n",
    "\n",
    "    Returns:\n",
    "    - Maximum conservation error and runtime for the solver.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    solver.SG_solver(box, Z, per_tol, tf, int(Ndt), per_x, per_y, per_z, debug=debug)\n",
    "    runtime = time.time() - start_time\n",
    "    \n",
    "    solver_name = solver_name_map[solver]\n",
    "    seeds, C, _, _, TC = aux.load_data(f'./data/{solver_name}_SG_data.msgpack')\n",
    "    _, _, _, _, E, _ = aux.get_properties(seeds, C, TC)\n",
    "    meanEnergy = np.mean(E)\n",
    "    ConservationError = np.abs((E - meanEnergy) / meanEnergy)\n",
    "\n",
    "    return max(ConservationError), runtime\n",
    "\n",
    "# Main loop\n",
    "solvers = [AB2, Heun, RK4, CN] # Assuming AB2, Heun, RK4, DOPRI are defined elsewhere\n",
    "data = {solver.__name__: [] for solver in solvers}\n",
    "\n",
    "for i in Ndt:\n",
    "    for solver in solvers:\n",
    "        error, runtime = run_test(solver, box, Z, per_tol, tf, i, per_x, per_y, per_z)\n",
    "        data[solver.__name__].append((error, runtime))\n",
    "    print(f\"Completed iteration with Ndt={i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate initial time step sizes for the x-axis\n",
    "initial_time_steps = tf / Ndt\n",
    "\n",
    "# Function to plot data for a specific solver\n",
    "def plot_solver_data(ax1, ax2, data, initial_time_steps, label, color):\n",
    "    max_errors = [d[0] for d in data]  # Extract max conservation errors\n",
    "    runtimes = [d[1] for d in data]  # Extract runtimes\n",
    "\n",
    "    ax1.plot(initial_time_steps, max_errors, label=f\"{label} Max Error\", color=color)\n",
    "    ax2.plot(initial_time_steps, runtimes, label=f\"{label} Runtime\", color=color, linestyle=\"--\")\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()  # Instantiate a second axes that shares the same x-axis\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'black']\n",
    "labels = ['mainAB2', 'mainHeun', 'mainRK4', 'mainCN']\n",
    "\n",
    "# Iterate through each solver and plot\n",
    "for solver, color in zip(labels, colors):\n",
    "    plot_solver_data(ax1, ax2, data[solver], initial_time_steps, solver, color)\n",
    "\n",
    "# Labeling the axes\n",
    "ax1.set_xlabel('Initial Time Step')\n",
    "ax1.set_ylabel('Max Conservation Error', color='tab:blue')\n",
    "ax2.set_ylabel('Runtime (sec)', color='tab:red')\n",
    "\n",
    "# Adding legends\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "# Display the plot\n",
    "plt.title('Comparison of ODE Solvers: Conservation Error and Runtime')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour plots of the temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a package to preform a nearest neighbour search\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Select the timestep you want to plot (e.g., 0 for the first timestep)\n",
    "a, b, c = 3.66, 1.75, 0.45 # Pull in the dimensions of the fundamental domain\n",
    "selected_timestep = 1114  # Adjust this as needed\n",
    "fixed_z = c # Set whether we are ploting the temperature on the surface or on the lid\n",
    "\n",
    "# First we compute the temperature and zip it to the corresponding centroid\n",
    "_, _, _, T, _, _ = aux.Properties(Z, C, TC)\n",
    "T_selected = T[selected_timestep, :, np.newaxis]  # T for selected timestep\n",
    "C_selected = C[selected_timestep]  # Positions for selected timestep\n",
    "CT_selected = np.concatenate((C_selected, T_selected), axis=1)  # Combine selected positions and temperatures\n",
    "\n",
    "# Set the shift value to ensure that the copies lie in [-2a,-a] and [a,2a]\n",
    "x_shift = 1.5 * a \n",
    "C_rs_selected = CT_selected.copy()\n",
    "C_ls_selected = CT_selected.copy()\n",
    "C_rs_selected[:, 0] += x_shift\n",
    "C_ls_selected[:, 0] -= x_shift\n",
    "\n",
    "# Combine the original and the two shifted centroid positions\n",
    "combined_positions = np.vstack((CT_selected, C_rs_selected, C_ls_selected))\n",
    "\n",
    "# Next we generate a grid containing all of the points on the surface or the lid for our contour plot. \n",
    "\n",
    "# Grid dimensions in x and y directions\n",
    "num_points_x = 1000  # Number of points in x\n",
    "num_points_y = 500   # Number of points in y\n",
    "\n",
    "# Generate grid points for x and y\n",
    "x = np.linspace(-a, a, num_points_x)\n",
    "y = np.linspace(-b, b, num_points_y)\n",
    "\n",
    "# Create meshgrid for x and y\n",
    "x_grid, y_grid = np.meshgrid(x, y)\n",
    "\n",
    "# Flatten the x and y grid arrays\n",
    "x_flat = x_grid.flatten()\n",
    "y_flat = y_grid.flatten()\n",
    "\n",
    "# Set the z coordinate\n",
    "z_flat = np.full_like(x_flat, fixed_z)  # Create an array filled with the fixed z value\n",
    "\n",
    "# Combine x, y, and z into a Mx3 matrix\n",
    "sample_points = np.vstack((x_flat, y_flat, z_flat)).T\n",
    "\n",
    "# Nearest neighbor search for the selected timestep\n",
    "tree = cKDTree(combined_positions[:, :3])  # Use positions only\n",
    "distances, indices = tree.query(sample_points, k=1)\n",
    "nearest_temperatures = combined_positions[indices, 3]\n",
    "\n",
    "# Prepare sample points with temperature for plotting\n",
    "sample_points_with_temp = np.hstack((sample_points, nearest_temperatures[:, np.newaxis]))\n",
    "xy_temp = sample_points_with_temp[:, [0, 1, 3]]\n",
    "\n",
    "# Reshaping and plotting as before\n",
    "temperatures_grid = xy_temp[:, 2].reshape((num_points_y, num_points_x))\n",
    "x_unique = np.unique(xy_temp[:, 0])\n",
    "y_unique = np.unique(xy_temp[:, 1])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cp = plt.contourf(x_unique, y_unique, temperatures_grid, cmap='coolwarm', levels=20)\n",
    "plt.colorbar(cp)\n",
    "plt.title(f'Temperature Contour Plot at Timestep {selected_timestep}')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
